{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_tools.utils.resource_calc import ModelConfig,SequenceConfig,DataTypeConfig,InferenceConfig\n",
    "from llm_tools.utils.resource_calc import MemoryCalc,ComputeCalc\n",
    "from llm_tools.utils.resource_calc import convert_unit_from_bytes,convert_unit_from_ops,concat_unit\n",
    "from llm_tools.utils.resource_calc import get_predefined_models,load_predefined_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = get_predefined_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Llama-2-7b-chat-hf', 'Meta-Llama-3-70B-Instruct', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-8B', 'Mistral-7B-Instruct-v0.3', 'Mixtral-8x7B-Instruct-v0.1', 'phi-2', 'Phi-3-mini-4k-instruct', 'Qwen2-72B-Instruct']\n"
     ]
    }
   ],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_config = load_predefined_model_config(model_name=model_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_tools.utils.resource_calc.ModelConfig'>\n"
     ]
    }
   ],
   "source": [
    "print(type(lm_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(lm_config=lm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_calc = ComputeCalc(inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_map = compute_calc.get_total_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decoding': 7012876288, 'prefill': 6906307411968}\n"
     ]
    }
   ],
   "source": [
    "print(ops_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.53125, 'GOPs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_unit_from_ops(ops_map['decoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decoding': 50331648, 'prefill': 51539607552}\n",
      "{'decoding': 33554432, 'prefill': 25769803776}\n",
      "{'decoding': 135266304, 'prefill': 138512695296}\n"
     ]
    }
   ],
   "source": [
    "print(compute_calc.get_layer_qkv_proj_ops())\n",
    "print(compute_calc.get_layer_attention_ops())\n",
    "print(compute_calc.get_layer_ffn_ops())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_calc = MemoryCalc(inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 7012876288.0, 'weight': 6476005376, 'kv_cache': 536870912.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_calc.get_total_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6607077376"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_calc.get_layer_weight_size() * 32  + inference_config.lm_config.hidden_size * inference_config.lm_config.vocab_size + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
